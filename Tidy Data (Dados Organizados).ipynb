{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy Data (Dados organizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadley Wickham, um dos memnros mais proeminentes da comunidade R, introduziu o conceito de tindy data (dados organizados) em um artigo do journal of statistical software. Tindy data é um framework para estruturar conjuntos de dados de modo que sejam facilmente analisados e visualizados. Podemos pensar nele como um objetivo a que devemos visar quando limpamos os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, o que é tidy data? O artigo de Handley Wickham o define como um conceito que atende aos seguintes critérios:\n",
    "    - Cada linha é uma observação (observation).\n",
    "    - Cada coluna é uma variável (variable).\n",
    "    - Cada tipo de unidade de observação forma uma tabela(observation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colunas contem Valores não variáveis\n",
    "Os dados podem ter colunas que contem valores em vez de variáveis. Em gera, é um formato conveniente para colta e apresentação de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matendo uma coluna fixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>religion</th>\n",
       "      <th>&lt;$10k</th>\n",
       "      <th>$10-20k</th>\n",
       "      <th>$20-30k</th>\n",
       "      <th>$30-40k</th>\n",
       "      <th>$40-50k</th>\n",
       "      <th>$50-75k</th>\n",
       "      <th>$75-100k</th>\n",
       "      <th>$100-150k</th>\n",
       "      <th>&gt;150k</th>\n",
       "      <th>Don't know/refused</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agnostic</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>137</td>\n",
       "      <td>122</td>\n",
       "      <td>109</td>\n",
       "      <td>84</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atheist</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buddhist</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>62</td>\n",
       "      <td>39</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Catholic</td>\n",
       "      <td>418</td>\n",
       "      <td>617</td>\n",
       "      <td>732</td>\n",
       "      <td>670</td>\n",
       "      <td>638</td>\n",
       "      <td>1116</td>\n",
       "      <td>949</td>\n",
       "      <td>792</td>\n",
       "      <td>633</td>\n",
       "      <td>1489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don’t know/refused</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k  \\\n",
       "0            Agnostic     27       34       60       81       76      137   \n",
       "1             Atheist     12       27       37       52       35       70   \n",
       "2            Buddhist     27       21       30       34       33       58   \n",
       "3            Catholic    418      617      732      670      638     1116   \n",
       "4  Don’t know/refused     15       14       15       11       10       35   \n",
       "\n",
       "   $75-100k  $100-150k  >150k  Don't know/refused  \n",
       "0       122        109     84                  96  \n",
       "1        73         59     74                  76  \n",
       "2        62         39     53                  54  \n",
       "3       949        792    633                1489  \n",
       "4        21         17     18                 116  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "O dataset do Pew Research Center é sobre renda e religião nos Estadus unimdos\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "pew = pd.read_csv('data/pew.csv')\n",
    "pew.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando o esse conjunto de dados, podemos ver que nem toda as colunas são variáveis. Os valores relacionados à reda estão espalhados em várias colunas. O formato exibido é uma ótima opção quando apresentamos dados em uma tabela, mas , para análise de dados, a tabela precisa ser reformatada a fim de que tenhamos variáveis para religião, renda e contador.<br>\n",
    "Essa visualização dos dados também é conhecida como dados 'largos'(wide). Para transforma-la no formato de dados longos (long) do tidy data, teremos que efetuar uma operação de fusão (unpivot/melt/gather) no nosso dataframe. Pandas tem a função chamada melt que reformatará o dataframe de maneira organizada. **melt** aceita alguns parâmetros:\n",
    "\n",
    "- **id_vars:** É um conteiner (lista, tupla e etcO que represnta as variáveis que permanecerão inalteradas.\n",
    "- **value_vars:** Identifica as colunas em que a operação de melt (fusão) será executada. Por padrão, ela será executada em  todas as cuonas não especificadas pelo *id_vars*. \n",
    "- **var_name:** é uma string para o nome da nova coluna quando um melt é executado em *value_vars*. Por padrão ela é chamada de **variable**.\n",
    "- **value_name:** é uma string para o nome da nova coluna que representa os valores para *var_name*. Por padrão, ela será chamada value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion variable  value\n",
      "0            Agnostic    <$10k     27\n",
      "1             Atheist    <$10k     12\n",
      "2            Buddhist    <$10k     27\n",
      "3            Catholic    <$10k    418\n",
      "4  Don’t know/refused    <$10k     15\n"
     ]
    }
   ],
   "source": [
    "# Não precisamos espeficar um value_vars, \n",
    "# pois queremos pivotear todas as colunas, exeto a coluna 'religion'\n",
    "pew_long = pd.melt(pew, id_vars='religion')\n",
    "print(pew_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos altearr os defauls de modo que as colunas sujeitas à operação do **melt** sejam nomeadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion income  cont\n",
      "0            Agnostic  <$10k    27\n",
      "1             Atheist  <$10k    12\n",
      "2            Buddhist  <$10k    27\n",
      "3            Catholic  <$10k   418\n",
      "4  Don’t know/refused  <$10k    15\n"
     ]
    }
   ],
   "source": [
    "pew_long = pd.melt(pew,\n",
    "                  id_vars ='religion',\n",
    "                  var_name ='income',\n",
    "                  value_name ='cont')\n",
    "print(pew_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mantendo várias colunas fixas \n",
    "Nem todo conjunto de dados terá uma coluna que permanecerá inalterada enquanto você executar um unpivot ('Despivotear') no restante das colunas. Como exemplo, considere o conjunto de dados billboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard = pd.read_csv('data/billboard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "0  72.0  77.0  87.0  94.0  99.0   NaN   NaN   NaN   NaN  \n",
      "1  92.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n"
     ]
    }
   ],
   "source": [
    "# observe as primeiras linhas e colunas\n",
    "print(billboard.iloc[0:5, 0:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver, nos dados acima, que cada semana tem suam proporia coluna, o que é bem normal. No entanto, pode haver um momento em que você precisará executar um melt nos dados. Por exemplo, se quisesse criar uma plotagem com faceta com as classificações semanais, a variavel faceta teria de ser uma coluna do dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1   \n",
      "\n",
      "   ratting  \n",
      "0     87.0  \n",
      "1     91.0  \n",
      "2     81.0  \n",
      "3     76.0  \n",
      "4     57.0  \n"
     ]
    }
   ],
   "source": [
    "billboard_long = pd.melt(\n",
    "            billboard,\n",
    "            id_vars= ['year', 'artist', 'track', 'time', 'date.entered'],\n",
    "            var_name='week',\n",
    "            value_name='ratting')\n",
    "\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colunas contendo diversas variáveis\n",
    "Colunas em um conjunto de dadpos podem representar diversas variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
      "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
      "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
      "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
      "       'Deaths_Spain', 'Deaths_Mali'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ebola = pd.read_csv('data/country_timeseries.csv')\n",
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Deaths_Guinea  Deaths_Liberia\n",
      "0    1/5/2015  289        2776.0            NaN         1786.0             NaN\n",
      "1    1/4/2015  288        2775.0            NaN         1781.0             NaN\n",
      "2    1/3/2015  287        2769.0         8166.0         1767.0          3496.0\n",
      "3    1/2/2015  286           NaN         8157.0            NaN          3496.0\n",
      "4  12/31/2014  284        2730.0         8115.0         1739.0          3471.0\n"
     ]
    }
   ],
   "source": [
    "#Exibindo linhas selecionadas\n",
    "print(ebola.iloc[:5, [0, 1, 2, 3, 10, 11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os nomes de colunas **Cases_Guinea e Deaths_Guinea** na verdade contêm duas variáveis: o status individual (casos e mortes, recpecitvamente), assim como o nome  do país, Guinea (Guiné). Os dados também estão organizados em formato largo, e a operação  de um umpivot deve ser executada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "ebola_long = pd.melt(ebola, id_vars=['Date', 'Day'])\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separar e adicionar colunas individualmente (método simples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Cases, Guinea]\n",
      "1    [Cases, Guinea]\n",
      "2    [Cases, Guinea]\n",
      "3    [Cases, Guinea]\n",
      "4    [Cases, Guinea]\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Obtém a coluna variable,\n",
    "# acessa os métodos de string\n",
    "# e separa a coluna com base em um delimitador\n",
    "variable_split = ebola_long.variable.str.split('_')\n",
    "print(variable_split[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois da separação com base nos underscore, os valores são devolvidos em uma lista. Sabemos se tratar de uma lista proque é assim que o método split funciona, mas a pista visual encontra-se no fato de o resultado estar cercado por colchetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# o contêiner inteiro\n",
    "print(type(variable_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que a coluna foi separada em várias partes, o próximo passo é atribuir essas partes a uma nova coluna. Inicialmente, porem, precisamos extrair todos os elementos com índice 0 da coluna de *status* e os elementos de índice 1 da coluna de país. Para isso, temos de acessar os métodos de string novamente e então usar o método *get* para obter o índice que queremos em cada linha. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Cases\n",
      "1    Cases\n",
      "2    Cases\n",
      "3    Cases\n",
      "4    Cases\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "status_values = variable_split.str.get(0)\n",
    "country_values = variable_split.str.get(1)\n",
    "print(status_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "# Agora que temos os vetores desejados, podemos adiciona-los em nosso dataframe.\n",
    "ebola_long['status'] = status_values\n",
    "ebola_long['country'] = country_values\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separar e combinar em um único passo (método simples)\n",
    "Nesta sessão, exploraremos o fato de que o vetor devolvido está na mesma ordem que nossos dados. Podemos concatenar o novo vetor aos nossos dados originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country         variable\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea  [Cases, Guinea]\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea  [Cases, Guinea]\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea  [Cases, Guinea]\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea  [Cases, Guinea]\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea  [Cases, Guinea]\n"
     ]
    }
   ],
   "source": [
    "variabe_split = ebola_long.variable.str.split('_', expand=True)\n",
    "variabe_split.columns = ['status', 'country']\n",
    "ebola_parsed = pd.concat([ebola_long, variable_split], axis=1)\n",
    "print(ebola_parsed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis Tanto em linhas quanto em colunas\n",
    "As vezes, os dados estarão formatados de modo que as variáveis se encontrarão tanto nas linhas quanto nas colunas. Apresentaremos o que acontecerá se uma coluna de dados armazenar duas variáveis em vez de uma. Nesse caso teremos que executar uma operação de pivot ou cast da variavel em colunas separadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element  d1    d2    d3  d4    d5  d6  d7\n",
      "0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "1  MX17004  2010      1    tmin NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "2  MX17004  2010      2    tmax NaN  27.3  24.1 NaN   NaN NaN NaN\n",
      "3  MX17004  2010      2    tmin NaN  14.4  14.4 NaN   NaN NaN NaN\n",
      "4  MX17004  2010      3    tmax NaN   NaN   NaN NaN  32.1 NaN NaN\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv('data/weather.csv')\n",
    "print(weather.iloc[:5, :11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados meteorológicos incluem temperaturas mínima e máxima (valores tmin e tmax na colnuna *element*, respectivamente) registradas para cada dia (d1, d2, ...,d31) do mês (month). A coluna *element* contém variáveis que devem ser submetidas a cast/pivot para que se trasformem em novas colunas, e as variáveis de dia devem ser sujeitas à operação de melt, gerando valores de linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element day  temp\n",
      "0  MX17004  2010      1    tmax  d1   NaN\n",
      "1  MX17004  2010      1    tmin  d1   NaN\n",
      "2  MX17004  2010      2    tmax  d1   NaN\n",
      "3  MX17004  2010      2    tmin  d1   NaN\n",
      "4  MX17004  2010      3    tmax  d1   NaN\n"
     ]
    }
   ],
   "source": [
    "# Vamos executar primeiro a operação de melt/unpivot nos valores dos dias.\n",
    "weather_melt = pd.melt(weather,\n",
    "                      id_vars=['id', 'year', 'month', 'element'],\n",
    "                      var_name='day',\n",
    "                      value_name='temp')\n",
    "print(weather_melt.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir devemos pivotear as variáveis armazenadas na coluna element. Esse processo é conhecido como casting ou spreading em outras linguagens estatísticas. Uma das principais diferenças entre *pivot_table* e *melt* é uma função no Pandas, enquanto *pivot_table* é um método que chamamos em um objeto DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id', 'year', 'month', 'day'],\n",
    "    columns='element',\n",
    "    values='temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observandoa table após a operação de pivot, percebemos que cada valor na coluna element está agora em uma coluna separada. É possível deixar essa tabela em seu estado atual, mas também podemos linearizar as colunas hierárquicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  month  day  tmax  tmin\n",
      "0        MX17004  2010      1  d30  27.8  14.5\n",
      "1        MX17004  2010      2  d11  29.7  13.4\n",
      "2        MX17004  2010      2   d2  27.3  14.4\n",
      "3        MX17004  2010      2  d23  29.9  10.7\n",
      "4        MX17004  2010      2   d3  24.1  14.4\n"
     ]
    }
   ],
   "source": [
    "weather_tidy_flat = weather_tidy.reset_index()\n",
    "print(weather_tidy_flat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  month  day  tmax  tmin\n",
      "0        MX17004  2010      1  d30  27.8  14.5\n",
      "1        MX17004  2010      2  d11  29.7  13.4\n",
      "2        MX17004  2010      2   d2  27.3  14.4\n",
      "3        MX17004  2010      2  d23  29.9  10.7\n",
      "4        MX17004  2010      2   d3  24.1  14.4\n"
     ]
    }
   ],
   "source": [
    "# Do mesmo modo, podemos aplicar esses métodos sem o dataframe intermediário:\n",
    "weather_tidy = weather_melt.\\\n",
    "    pivot_table(\n",
    "        index=['id', 'year', 'month', 'day'],\n",
    "        columns='element',\n",
    "        values='temp').\\\n",
    "    reset_index()\n",
    "print(weather_tidy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Várias unidades de observação em uma tabela(normalização)\n",
    "um dos modos mais simples de saber se várias unidades de observação estão represetadas em uma tabela é observar cada uma das linha e prestar atenção se há alguma célula ou valor sendo repetido nas linhas. Isso é muito comum em dados administrativos de educação do governo, em que informações demofráficas de estudantes são informadas para cada aluno, para cada ano em que esse aluno estiver matriculado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1   \n",
      "\n",
      "   ratting  \n",
      "0     87.0  \n",
      "1     91.0  \n",
      "2     81.0  \n",
      "3     76.0  \n",
      "4     57.0  \n"
     ]
    }
   ],
   "source": [
    "# Observemos novamente os dados da Billboard que limpamos anteriormente.\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponhamos que tenhamos criado um subconjunto dos dados com base em uma faiza musical em particular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year        artist  track  time date.entered week  ratting\n",
      "3     2000  3 Doors Down  Loser  4:24   2000-10-21  wk1     76.0\n",
      "320   2000  3 Doors Down  Loser  4:24   2000-10-21  wk2     76.0\n",
      "637   2000  3 Doors Down  Loser  4:24   2000-10-21  wk3     72.0\n",
      "954   2000  3 Doors Down  Loser  4:24   2000-10-21  wk4     69.0\n",
      "1271  2000  3 Doors Down  Loser  4:24   2000-10-21  wk5     67.0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_long[billboard_long.track =='Loser'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que essa tabela, na verdade, armazena dois tipos de dados: a informação da faiza musical (track) e a classificação semanal. Dessa forma,  as informações armazenadas nas colunas year, artist, track e time não estariam repedidas no conjunto de dados. Essa consideração é particularmente importante se os dados forem inseridos manualmente. Repetir os mesmos valores de modo contínuo durante a entreda de dados eleva o risco de haver dados inconsistentes.\n",
    "\n",
    "O que deveríamos fazer nesse caso é colocar year, artist, track, time e date.enterde em um novo dataframe, com cada conjunto unico de valores recevendo um ID único. Podemos então usar esse ID único em um segundo dataframe que represente a música, a data, o número da semana e a classificação. Esse processo como um todo pode ser pensado com uma inversão dos passos de concatenação e combinação de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 4)\n"
     ]
    }
   ],
   "source": [
    "billboard_songs = billboard_long[['year', 'artist', 'track','time']]\n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Sabemos que há entradas duplicadas nesse dataframe, portanto devemos descartas as linhas duplicadas.\n",
    "'''\n",
    "billboard_songs = billboard_songs.drop_duplicates()\n",
    "billboard_songs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos então atribuir um valor unico para cada linha de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year          artist                    track  time  id\n",
      "0  2000           2 Pac  Baby Don't Cry (Keep...  4:22   0\n",
      "1  2000         2Ge+her  The Hardest Part Of ...  3:15   1\n",
      "2  2000    3 Doors Down               Kryptonite  3:53   2\n",
      "3  2000    3 Doors Down                    Loser  4:24   3\n",
      "4  2000        504 Boyz            Wobble Wobble  3:35   4\n",
      "5  2000            98^0  Give Me Just One Nig...  3:24   5\n",
      "6  2000         A*Teens            Dancing Queen  3:44   6\n",
      "7  2000         Aaliyah            I Don't Wanna  4:15   7\n",
      "8  2000         Aaliyah                Try Again  4:03   8\n",
      "9  2000  Adams, Yolanda            Open My Heart  5:30   9\n"
     ]
    }
   ],
   "source": [
    "billboard_songs['id'] = range(len(billboard_songs))\n",
    "print(billboard_songs.head(n=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos um dataframe separado com as músicas, podemos usar a colina id recém criada para fazer uma correspondencia entre uma música e sua classificação semanal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 8)\n"
     ]
    }
   ],
   "source": [
    "# Combina o dataframe de música com o conjunto de dados original\n",
    "billboard_ratings = billboard_long.merge(\n",
    "    billboard_songs, on=['year', 'artist', 'track', 'time'])\n",
    "print(billboard_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year artist                    track  time date.entered week  ratting  id\n",
      "0  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1     87.0   0\n",
      "1  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk2     82.0   0\n",
      "2  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk3     72.0   0\n",
      "3  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk4     77.0   0\n",
      "4  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk5     87.0   0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vamos obter um subconjunto com as colunas que queremos em nosso dataframe de classificações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id date.entered week  ratting\n",
      "0   0   2000-02-26  wk1     87.0\n",
      "1   0   2000-02-26  wk2     82.0\n",
      "2   0   2000-02-26  wk3     72.0\n",
      "3   0   2000-02-26  wk4     77.0\n",
      "4   0   2000-02-26  wk5     87.0\n"
     ]
    }
   ],
   "source": [
    "billboard_ratings = \\\n",
    "    billboard_ratings[['id', 'date.entered', 'week', 'ratting']]\n",
    "print(billboard_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ultima porão da organização dos dados relaciona-se à situação em que o mesmo tipo de dado está espalhado por vários conjuntos de dados. Um dos motivos pelos quais os dados podem estar separados em varios arquivos é devido ao tamanho destes. Ao separar os dados em várias partes, cada uma delas se torna menor. Isso pode ser bom se houver necessidade de compartilhar dados na internet ou por emaiol, pois muitos serviçoes limitam o tamanho de um arquivo que pode ser aberto ou compartilhado. O processo de coleta de dados é outro motivo pelo qual um conjunto de dados separado contendo informações sobre ações no mercado poderia ser criado a cada dia.\n",
    "\n",
    "O Unifed New York City Taxi and Uber Data será o data set que iremos trabalhar. este dataset contem o histórico de 1,3 bilhoes de corridas de taxi e uber na cidade de NY e está organizado em mais de 140 arquivos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-01.csv\n",
      "\n",
      "..\\data\\fhv_tripdata_2015-01.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\data\\\\fhv_tripdata_2015-01.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-2dab9a74aad6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;31m# Handle temporary file setup.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m             \u001b[0mtfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mtfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNamedTemporaryFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\data\\\\fhv_tripdata_2015-01.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "# Código para fazer download dos dados;\n",
    "# faz o download somente dos cinco primeiro conjunto de dados da lista de arquivos\n",
    "with open('data/raw_data_urls.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:\n",
    "            break\n",
    "        fn = url.split('/')[-1].strip()\n",
    "        fp = os.path.join('..', 'data', fn)\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
